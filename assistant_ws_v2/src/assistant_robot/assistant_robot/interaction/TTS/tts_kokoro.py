import re
import numpy as np
import soundfile as sf
import torch
from kokoro import KModel, KPipeline
from pathlib import Path
import time
import sounddevice as sd
from queue import Queue
from threading import Thread
import cn2an
import inflect

import logging
logging.getLogger("TTS").setLevel(logging.ERROR)
from assistant_robot.interaction.TTS.tts_interface import TTS

class KokoroTTS(TTS):
    def __init__(self):
        # ---------------------
        # é…ç½®
        # ---------------------
        self.SAMPLE_RATE = 24000
        DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'

        ZH_REPO = 'hexgrad/Kokoro-82M-v1.1-zh'
        EN_REPO = 'hexgrad/Kokoro-82M' 
        self.VOICE_ZH = 'zf_001'
        self.VOICE_EN = 'af_heart'
        N_ZEROS = 3000  # é™éŸ³è¿‡æ¸¡
        # æ ¹æ®æ ‡ç‚¹æ’å…¥ä¸åŒé™éŸ³é•¿åº¦ï¼ˆå•ä½æ˜¯é‡‡æ ·ç‚¹ï¼Œsample_rate=24000ï¼‰
        self.PAUSE_LONG = int(0.5 * self.SAMPLE_RATE)   # å¥å·ã€é—®å·ã€æ„Ÿå¹å·
        self.PAUSE_SHORT = int(0.25 * self.SAMPLE_RATE) # é€—å·ã€é¡¿å·ã€åˆ†å·

        # ---------------------
        # åˆå§‹åŒ–ä¸­è‹±æ–‡æ¨¡åž‹
        # ---------------------
        self.model_zh = KModel(repo_id=ZH_REPO).to(DEVICE).eval()
        self.zh_pipeline = KPipeline(lang_code='z', repo_id=ZH_REPO, model=self.model_zh)

        self.model_en = KModel(repo_id=EN_REPO).to(DEVICE).eval()
        self.en_pipeline = KPipeline(lang_code='a', repo_id=EN_REPO, model=self.model_en)

        self._play_queue = Queue()
        self._play_thread = Thread(target=self._playback_worker, daemon=True)
        self._play_thread.start()
    
    def _playback_worker(self):
        """åŽå°çº¿ç¨‹ï¼Œä»Žé˜Ÿåˆ—å–å‡º wav å¹¶æŒ‰é¡ºåºæ’­æ”¾ï¼ˆé˜»å¡žå¼ï¼‰"""
        while True:
            wav = self._play_queue.get()
            if wav is None:
                break
            sd.play(wav, samplerate=self.SAMPLE_RATE)
            sd.wait()

    def _normalize_numbers(self, lang, text):
        """æ•°å­—é¢„å¤„ç†ï¼šä¸­æ–‡è½¬ä¸­æ–‡æ•°å­—ï¼Œè‹±æ–‡è½¬è‹±æ–‡è¯»æ³•"""
        if lang == 'zh':
            def replace_num(match):
                num_str = match.group()
                try:
                    return cn2an.an2cn(num_str, "smart")
                except Exception:
                    return num_str
            return re.sub(r'\d+(\.\d+)?', replace_num, text)

        elif lang == 'en':
            p = inflect.engine()
            def replace_num(match):
                num_str = match.group()
                try:
                    # è½¬æˆè‹±æ–‡è¯»æ³•ï¼ŒåŽ»æŽ‰ andï¼ˆé¿å… too Britishï¼‰
                    return p.number_to_words(num_str, andword="")
                except Exception:
                    return num_str
            return re.sub(r'\d+(\.\d+)?', replace_num, text)

        return text



    def _split_text_mixed(self,text):
        """
        æŒ‰ä¸­æ–‡å’Œè‹±æ–‡åˆ†æ®µï¼Œæ ‡ç‚¹å½’ä¸­æ–‡ï¼ˆæˆ–è‹±æ–‡ï¼‰ä¸å•ç‹¬æ‹†å‡ºã€‚
        """
        # pattern = re.compile(r'[\u4e00-\u9fff]+|[a-zA-Z0-9\s]+|[ï¼Œã€‚ï¼ï¼Ÿ,.!?]')  # å…ˆæ‹†ä¸­è‹±æ–‡ä¸»ä½“ï¼ˆåŽ»é™¤æ ‡ç‚¹ï¼‰
        pattern = re.compile(r'[\u4e00-\u9fff0-9]+|[a-zA-Z]+|[ï¼Œã€‚ï¼ï¼Ÿï¼›ã€,.!?]')

        result = []
        buffer = ''
        current_lang = None

        for m in pattern.finditer(text):
            seg = m.group(0)
            if re.match(r'[ï¼Œã€‚ï¼ï¼Ÿ,.!?]', seg):  # æ ‡ç‚¹
                # æ ‡ç‚¹åŠ åˆ°ç¼“å†²é‡Œ
                buffer += seg
            else:
                lang = 'zh' if re.search(r'[\u4e00-\u9fff]', seg) else 'en'
                # å¦‚æžœåˆ‡æ¢è¯­è¨€ï¼Œå…ˆå­˜ç¼“å†²
                if current_lang is not None and lang != current_lang and buffer:
                    result.append((current_lang, buffer))
                    buffer = seg
                    current_lang = lang
                else:
                    buffer += seg
                    current_lang = lang
        if buffer:
            result.append((current_lang, buffer))
        return result

    # ---------------------
    # è¯­éŸ³åˆæˆ
    # ---------------------
    def _synthesize(self,lang, text):
        if not text.strip():
            return np.array([], dtype=np.float32)
        if lang == 'zh':
            generator = self.zh_pipeline(text, voice=self.VOICE_ZH)
        else:
            generator = self.en_pipeline(text, voice=self.VOICE_EN)

        try:
            return next(generator).audio
        except StopIteration:
            print(f"è­¦å‘Š: è¯­éŸ³ç”Ÿæˆç©ºï¼Œè·³è¿‡æ®µè½: {text}")
            return np.array([], dtype=np.float32)

    def _get_pause_duration(self,text_segment):
        """
        åˆ¤æ–­æ–‡æœ¬æœ«å°¾æ ‡ç‚¹ç¬¦å·ç±»åž‹ï¼Œè¿”å›žå¯¹åº”é™éŸ³é•¿åº¦é‡‡æ ·ç‚¹æ•°
        """
        if not text_segment:
            return 0
        last_char = text_segment[-1]
        if last_char in ['ã€‚', 'ï¼', 'ï¼Ÿ','ï¼š', '.', '!', '?',':']:
            return self.PAUSE_LONG
        elif last_char in ['ï¼Œ', 'ã€','ï¼›', ',', 'ï¼Œ',';']:
            return self.PAUSE_SHORT
        else:
            return 0 
        
    # ---------------------
    # ä¸»åˆæˆå‡½æ•°
    # ---------------------
    def _tts_mixed(self,text):
        parts = self._split_text_mixed(text)
        wavs = []
        for i, (lang, segment) in enumerate(parts):
            # print(f"åˆæˆç¬¬{i+1}æ®µï¼Œè¯­è¨€={lang}ï¼Œå†…å®¹ï¼š{segment}")
            segment = self._normalize_numbers(lang, segment)
            audio = self._synthesize(lang, segment)
            pause_len = self._get_pause_duration(segment)
            if i > 0 and pause_len > 0:
                audio = np.concatenate([np.zeros(pause_len), audio])
            wavs.append(audio)
        
        print(f"ðŸ”Š [TTS] æ’­æŠ¥: {text}")
        return np.concatenate(wavs) if wavs else np.array([], dtype=np.float32)
    
    def speak(self,text):
        wav = self._tts_mixed(text)
        if wav.size > 0:
            self._play_queue.put(wav)
        # sd.play(wav, samplerate=self.SAMPLE_RATE)
        # sd.wait()
