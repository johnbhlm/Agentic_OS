import pyaudio, wave, threading, time, re, os
import sounddevice as sd
import webrtcvad
from queue import Queue
from datetime import datetime, timedelta
from pypinyin import pinyin, Style
import sys
import subprocess
import logging
import numpy as np
from threading import Lock,Event
from assistant_robot.common.utils import convert_to_pinyin

logger = logging.getLogger(__name__)

# =======================
# çŠ¶æ€å®šä¹‰
# =======================
STATE_IDLE = "IDLE"            # æœªå”¤é†’çŠ¶æ€
STATE_WAKE_DETECTED = "WAKE"   # å”¤é†’è¯æ£€æµ‹
STATE_LISTENING = "LISTENING"  # æ­£åœ¨å½•åˆ¶æŒ‡ä»¤
STATE_PROCESSING = "PROCESSING" # æŒ‡ä»¤å¤„ç†ä¸­
STATE_SPEAKING = "SPEAKING"    # TTS æ’­æŠ¥ä¸­


class SessionContext:
    """ä¼šè¯ä¸Šä¸‹æ–‡ç®¡ç†"""
    def __init__(self, timeout=30.0):
        self.session_id = None
        self.start_time = None
        self.last_interaction = None
        self.timeout = timeout

    def start(self):
        self.session_id = f"session_{int(time.time()*1000)}"
        self.start_time = time.time()
        self.last_interaction = self.start_time
        logger.info(f"Session started: {self.session_id}")

    def update(self):
        self.last_interaction = time.time()

    def expired(self):
        return self.last_interaction and (time.time() - self.last_interaction > self.timeout)

    def reset(self):
        logger.info(f"Session reset: {self.session_id}")
        self.session_id = None
        self.start_time = None
        self.last_interaction = None

class SpeechManager:
    def __init__(self,transcriber,tts,
                 kws: str = "ni hao si ling", #xiao ai tong xue
                 rate: int = 16000,
                 vad_mode: int = 3,
                 chunk: int = 1024,
                 session_timeout: float = 180.0,
                 min_record_time: float = 0.5,
                 no_speech_threshold: float = 1.5,
                 max_command_duration: float = 10.0,):
        """
        :param kws: å”¤é†’è¯ï¼ˆæ‹¼éŸ³å½¢å¼ï¼‰
        :param rate: é‡‡æ ·ç‡
        :param vad_mode: webrtcvad æ•æ„Ÿåº¦ 0-3
        :param chunk: æ¯æ¬¡è¯»å–å¸§æ•°
        """
        self.transcriber = transcriber 
        self.tts = tts
        # self._confirm = confirm_fn
        self.kws = kws

        # audio settings
        self.rate = rate
        self.FORMAT = pyaudio.paInt16
        self.CHANNELS = 1
        self.CHUNK = chunk
        self.AUDIO_FILE = "temp.wav"  # ASR ä¸´æ—¶æ–‡ä»¶
        self.AUDIO_Denoise_FILE = "temp_denoise.wav"  # ASR ä¸´æ—¶æ–‡ä»¶

        # timing thresholds
        # self.waited_kws_time = waited_kws_time # å”¤é†’åç­‰å¾…å‘½ä»¤çš„æœ€å¤§æ—¶é•¿
        self.MIN_RECORD_TIME = min_record_time # æœ€å°å½•éŸ³æ—¶é•¿ï¼Œç§’
        self.NO_SPEECH_THRESHOLD = no_speech_threshold # é™éŸ³ååœæ­¢å½•åˆ¶ï¼Œç§’
        self.MAX_COMMAND_DURATION = max_command_duration

        # session and state
        # çŠ¶æ€ä¸ä¼šè¯
        self.state = STATE_IDLE
        self.session = SessionContext(timeout=session_timeout)
        self.state_lock = Lock()
        self.wake_event = Event()

        # TTS / interruption
        self.is_speaking = False       # TTS æ’­æŠ¥
        self.interrupt = False         # ç”¨æˆ·æ’è¯æ‰“æ–­æ ‡å¿—

        # vad
        self.vad = webrtcvad.Vad()
        self.vad.set_mode(vad_mode)
        self.audio_queue = Queue()

        # æŠ‘åˆ¶é€»è¾‘
        # self.suppress_until = 0.0     # æŠ‘åˆ¶æ£€æµ‹çš„æˆªæ­¢æ—¶é—´
        # self.kws_threshold = 0.8     # è°ƒé«˜å”¤é†’é˜ˆå€¼ï¼Œå‡å°‘è¯¯è§¦å‘
        # self.suppress_reset_sec = 5.0
        # self.suppress_tts_sec = 3.0

        self.transcribe_callback = None         
        
    def set_state(self, new_state):
        with self.state_lock:
            logger.info(f"State changed: {self.state} -> {new_state}")
            self.state = new_state

    def get_state(self):
        with self.state_lock:
            return self.state
        
    def set_transcription_callback(self, callback):
        self.transcribe_callback = callback

    # =======================
    # éŸ³é¢‘ä¸ASR
    # =======================
    def _is_valid_audio_input(self, audio_input, threshold: float = 500):
        """
        åˆ¤æ–­éŸ³é¢‘æ˜¯å¦ä¸ºæœ‰æ•ˆè¯­éŸ³ï¼Œæ”¯æŒåŸå§‹ bytes æˆ– list[bytes] è¾“å…¥ã€‚
        """
        if not audio_input:
            return False

        if isinstance(audio_input, list):
            audio_bytes = b''.join(audio_input)
        elif isinstance(audio_input, bytes):
            audio_bytes = audio_input
        else:
            logger.error("æ— æ•ˆçš„éŸ³é¢‘è¾“å…¥ç±»å‹")
            return False

        pcm_data = np.frombuffer(audio_bytes, dtype=np.int16)
        return np.max(np.abs(pcm_data)) > threshold

    def _check_vad_activity(self, audio_data):
        num, rate = 0, 0.4
        step = int(self.rate * 0.02)
        flag_rate = round(rate * len(audio_data) // step)

        for i in range(0, len(audio_data), step):
            chunk = audio_data[i:i + step]
            if len(chunk) == step and self.vad.is_speech(chunk, sample_rate=self.rate):
                num += 1

        return num > flag_rate
    
    # =======================
    # å”¤é†’ & ä¼šè¯ç®¡ç†
    # =======================
    def _asr_wake_up(self, text: str) -> bool:
        """
        å¤„ç†å”¤é†’è¯æ£€æµ‹å¹¶å”¤é†’
        """
        pinyin_text = convert_to_pinyin(text)
        if self.kws in pinyin_text:                
            logger.info("wake_up: key works detected and wake up sucess")
            return True
        logger.info("wake_up: key works detect fail,wake up fail")
        return False

    def _wake_up(self):
        """
        è§¦å‘å”¤é†’æµç¨‹
        """
        self._speak("åœ¨å‘¢ï¼Œè¯·è®²ã€‚")
        self.session.start()
        self.set_state(STATE_LISTENING)
        logger.info("wake_up: key works detected and wake up sucess")
    # =======================
    # ä¼šè¯è¿‡æœŸæ£€æŸ¥
    # =======================
    def _check_session_expired(self):
        if self.session.expired():
            self._speak("æ‚¨å¤ªä¹…æ²¡æœ‰è¯´è¯äº†ï¼Œæˆ‘å…ˆé€€ä¸‹äº†ï¼Œå¦‚éœ€å¸®åŠ©è¯·å†æ¬¡å”¤é†’æˆ‘ã€‚")
            self.session.reset()
            self.set_state(STATE_IDLE)
    
    def reset(self):
        self.session.reset()
        with self.audio_queue.mutex:
            self.audio_queue.queue.clear()# æ¸…ç©ºé˜Ÿåˆ—ï¼Œé˜²æ­¢æ®‹ç•™éŸ³é¢‘è§¦å‘
        self.set_state(STATE_IDLE)
        # self.suppress_until = time.time() + self.suppress_reset_sec  # reset åæŠ‘åˆ¶
        # logger.info(f"Reset: å›åˆ° WAKE æ¨¡å¼ ({self.suppress_reset_sec} s æŠ‘åˆ¶)")

    # =======================
    # TTS
    # =======================
    def _speak(self, text: str):
        def _run():
            # self.suppress_until = time.time() + self.suppress_tts_sec  # æ’­æ”¾æœŸé—´+3ç§’æŠ‘åˆ¶
            #æŒ‰æ’­æŠ¥æ–‡æœ¬é•¿åº¦åŠ¨æ€è°ƒæ•´æŠ‘åˆ¶æ—¶é•¿ï¼Œç¡®ä¿æ•´ä¸ª TTS æ’­æ”¾è¿‡ç¨‹éƒ½è¢«è¦†ç›–ã€‚
            # self.suppress_until = time.time() + max(self.suppress_tts_sec, len(text) * 0.5)

            self.is_speaking = True
            try:
                self.tts.speak(text)
            finally:
                self.is_speaking = False
        threading.Thread(target=_run, daemon=True).start()
    
    # =======================
    # æŒ‡ä»¤ç›‘å¬
    # =======================
    def _listen_command(self):
        """
        å”¤é†’åï¼ŒåŸºäº VAD å½•åˆ¶ç”¨æˆ·å‘½ä»¤ï¼Œé™éŸ³æˆ–æœ€é•¿è¶…æ—¶ååœæ­¢
        """
        # self.set_state(STATE_LISTENING)

        p = pyaudio.PyAudio()
        stream = p.open(format=self.FORMAT,channels=self.CHANNELS,rate=self.rate,input=True,frames_per_buffer=self.CHUNK)

        segments = []
        last_active = time.time()
        start_time = time.time()
        logger.info("Recording command...")

        while True:
            data = stream.read(self.CHUNK, exception_on_overflow=False)
            if self._check_vad_activity(data):
                segments.append(data)
                last_active = time.time()
            # è¶…æ—¶æˆ–æ£€æµ‹åˆ°é™éŸ³è¶…è¿‡é—¨æ§›å³ç»“æŸå½•åˆ¶
            if time.time() - last_active > self.NO_SPEECH_THRESHOLD or time.time() - start_time > self.MAX_COMMAND_DURATION:
                logger.info("è¶…æ—¶æˆ–æ£€æµ‹åˆ°é™éŸ³è¶…æ—¶,ç»“æŸå½•åˆ¶")
                break
        stream.stop_stream()
        stream.close()
        p.terminate()

        if not segments or not self._is_valid_audio_input(segments):
            logger.info("æ— æ•ˆçš„æŒ‡ä»¤éŸ³é¢‘ï¼Œï¼Œç»§ç»­ç›‘å¬")
            # self.reset()
            return

        # save to WAV file 
        with wave.open(self.AUDIO_FILE, 'wb') as wf:
            wf.setnchannels(self.CHANNELS)
            wf.setsampwidth(p.get_sample_size(self.FORMAT))
            wf.setframerate(self.rate)
            wf.writeframes(b''.join(segments))
        
        # #*************  start denoise ******************
        # env = os.environ.copy()
        # env["LD_LIBRARY_PATH"] = "/home/maintenance/Code/assistant_ws/src/assistant_robot_v2/assistant_robot/interaction/ASR/Denoise/2025.7.18/WavNoiseReduction-linux-x86_64/WavNoiseReduction/lib:" + env.get("LD_LIBRARY_PATH", "")
        
        # result = subprocess.run(
        #     ["/home/maintenance/Code/assistant_ws/src/assistant_robot_v2/assistant_robot/interaction/ASR/Denoise/2025.7.18/WavNoiseReduction-linux-x86_64/WavNoiseReduction/WavNoiseReduction",
        #      "/home/maintenance/Code/assistant_ws/src/assistant_robot_v2/assistant_robot/temp.wav",
        #      "/home/maintenance/Code/assistant_ws/src/assistant_robot_v2/assistant_robot/temp_denoise.wav"],
        #     env=env
        # )
        
        
        # self.set_state(STATE_PROCESSING)

        # ASR è½¬å†™å‘½ä»¤
        try:
            text = self.transcriber.transcribe(self.AUDIO_FILE)
            logger.info(f"ğŸ§¾ [ASR] è¯†åˆ«ç»“æœ: {text}")
            print(f"ğŸ§¾ [ASR] è¯†åˆ«ç»“æœ: {text}")
        except Exception as e:
            logger.info(" ASR å¤±è´¥")
            logger.error("ASR error: %s", e, exc_info=True)
            # self.reset()
            return

        # filter
        # if len(text) < 2 or re.fullmatch(r"[å•Šå—¯å“¦å”‰]*", text):
        if len(text) < 2 or re.fullmatch(r"^(å—¯|å•Š|å“¦|å”‰|å‘ƒ|å•Šå“ˆ|å””|å—¯å—¯|å‘ƒå‘ƒ|å“å‘€|å¯¹å‘€|æ˜¯å•Š|æ˜¯å‘€)$", text):
            logger.info("æŒ‡ä»¤è¿‡çŸ­æˆ–æ— æ•ˆ")
            # self.reset()
            return
    
        logger.info(f"ASR è¯†åˆ«æˆåŠŸï¼Œç”¨æˆ·æŒ‡ä»¤: {text}")

        # self.session.update()
        
        # æŠŠæ–‡æœ¬äº¤ç»™ä¸Šå±‚å›è°ƒ
        if self.transcribe_callback:
            self.transcribe_callback(text)

    # =======================
    # ä¸»å¾ªç¯
    # =======================
    def _record_audio_loop(self):        
        logger.info("ğŸ‘‚ å¼€å§‹å”¤é†’è¯ç›‘å¬...") 
        while True:
            current_state = self.get_state()

            # ä¼šè¯è¿‡æœŸæ£€æŸ¥
            if current_state in [STATE_LISTENING, STATE_PROCESSING]:
                if self.session.expired():
                    self._speak("æœ¬æ¬¡å¯¹è¯å·²è¶…æ—¶ï¼Œå°†ç»“æŸå¯¹è¯ï¼Œå¦‚éœ€å¸®åŠ©è¯·å†æ¬¡å”¤é†’æˆ‘ã€‚")
                    self.reset()
                    continue

            # ç©ºé—²çŠ¶æ€ -> ç­‰å¾…å”¤é†’
            if current_state == STATE_IDLE:
                sys.stdout.write("ğŸš¨ ç­‰å¾…å”¤é†’...\r")
                sys.stdout.flush()
                if self.wake_event.wait(timeout=0.1):
                    self.wake_event.clear()
                    self._wake_up()
                continue

            # æŒ‡ä»¤ç›‘å¬
            elif current_state == STATE_LISTENING:
                sys.stdout.write("ğŸ™ï¸ å·²å”¤é†’ï¼Œç›‘å¬æŒ‡ä»¤ä¸­...\r")
                sys.stdout.flush()
                self._listen_command()
                # self.reset()
                continue

            time.sleep(0.05) # é¿å… CPU å ç”¨è¿‡é«˜
  
            
    def start(self):
        thread = threading.Thread(target=self._record_audio_loop,daemon = True)
        thread.start()

    