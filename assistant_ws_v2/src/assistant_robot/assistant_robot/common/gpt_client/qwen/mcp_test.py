import os
from qwen_agent.agents import Assistant

import urllib
import requests


# ğŸš« å¼ºåˆ¶å…³é—­æ‰€æœ‰ä»£ç†
for key in ["HTTP_PROXY", "HTTPS_PROXY", "ALL_PROXY", "http_proxy", "https_proxy", "all_proxy", "FTP_PROXY", "ftp_proxy"]:
    os.environ.pop(key, None)
os.environ["NO_PROXY"] = "*"

# ğŸ§© ç¦ç”¨ requests å¯¹ç³»ç»Ÿä»£ç†çš„ä¿¡ä»»
session = requests.Session()
session.trust_env = False

# LLM é…ç½®
llm_cfg = {
    "model": "qwen-plus-latest",
    "model_server": "https://dashscope.aliyuncs.com/compatible-mode/v1",
    # è‹¥æ²¡æœ‰é…ç½®ç¯å¢ƒå˜é‡ï¼Œè¯·ç”¨é˜¿é‡Œäº‘ç™¾ç‚¼API Keyå°†ä¸‹è¡Œæ›¿æ¢ä¸ºï¼šapi_key="sk-xxx"
    # "api_key": os.getenv("DASHSCOPE_API_KEY"),
    "api_key": "sk-b2d24ce815fb46cf9aba319e7a5b43a1",
}

# ç³»ç»Ÿæ¶ˆæ¯
system = "ä½ æ˜¯ä¼šå¤©æ°”æŸ¥è¯¢ã€åœ°å›¾æŸ¥è¯¢ã€ç½‘é¡µéƒ¨ç½²çš„åŠ©æ‰‹"

# å·¥å…·åˆ—è¡¨
tools = [
    {
        "mcpServers": {
            "amap-maps": {
                "type": "sse",
                # æ›¿æ¢ä¸ºæ‚¨çš„ URL
                "url": "https://mcp.api-inference.modelscope.net/2c30b7dc5d024b/sse",
            },
            "edgeone-pages-mcp": {
                "type": "sse",
                # æ›¿æ¢ä¸ºæ‚¨çš„ URL
                "url": "https://mcp.api-inference.modelscope.net/6ade05ae13ec43/sse",
            },
        }
    }
]

# åˆ›å»ºåŠ©æ‰‹å®ä¾‹
bot = Assistant(
    llm=llm_cfg,
    name="åŠ©æ‰‹",
    description="é«˜å¾·åœ°å›¾ã€å¤©æ°”æŸ¥è¯¢ã€å…¬ç½‘é“¾æ¥éƒ¨ç½²",
    system_message=system,
    function_list=tools,
)

messages = []

while True:
    query = input("\nuser question: ")
    if not query.strip():
        print("user question cannot be emptyï¼")
        continue
    messages.append({"role": "user", "content": query})
    bot_response = ""
    is_tool_call = False
    tool_call_info = {}
    for response_chunk in bot.run(messages):
        new_response = response_chunk[-1]
        if "function_call" in new_response:
            is_tool_call = True
            tool_call_info = new_response["function_call"]
        elif "function_call" not in new_response and is_tool_call:
            is_tool_call = False
            # print("\n" + "=" * 20)
            # print("å·¥å…·è°ƒç”¨ä¿¡æ¯ï¼š", tool_call_info)
            # print("å·¥å…·è°ƒç”¨ç»“æœï¼š", new_response)
            # print("=" * 20)
        elif new_response.get("role") == "assistant" and "content" in new_response:
            incremental_content = new_response["content"][len(bot_response):]
            print(incremental_content, end="", flush=True)
            bot_response += incremental_content
    messages.extend(response_chunk)