import os
import urllib
import requests
from openai import OpenAI

# ğŸš« å¼ºåˆ¶å…³é—­æ‰€æœ‰ä»£ç†
for key in ["HTTP_PROXY", "HTTPS_PROXY", "ALL_PROXY", "http_proxy", "https_proxy", "all_proxy", "FTP_PROXY", "ftp_proxy"]:
    os.environ.pop(key, None)
os.environ["NO_PROXY"] = "*"

# ğŸ§© ç¦ç”¨ requests å¯¹ç³»ç»Ÿä»£ç†çš„ä¿¡ä»»
session = requests.Session()
session.trust_env = False

client = OpenAI(
    # è‹¥æ²¡æœ‰é…ç½®ç¯å¢ƒå˜é‡ï¼Œè¯·ç”¨é˜¿é‡Œäº‘ç™¾ç‚¼API Keyå°†ä¸‹è¡Œæ›¿æ¢ä¸ºï¼šapi_key="sk-xxx",
    # æ–°åŠ å¡å’ŒåŒ—äº¬åœ°åŸŸçš„API Keyä¸åŒã€‚è·å–API Keyï¼šhttps://help.aliyun.com/zh/model-studio/get-api-key
    api_key="sk-b2d24ce815fb46cf9aba319e7a5b43a1",
    # ä»¥ä¸‹æ˜¯åŒ—äº¬åœ°åŸŸbase_urlï¼Œå¦‚æœä½¿ç”¨æ–°åŠ å¡åœ°åŸŸçš„æ¨¡å‹ï¼Œéœ€è¦å°†base_urlæ›¿æ¢ä¸ºï¼šhttps://dashscope-intl.aliyuncs.com/compatible-mode/v1
    base_url="https://dashscope.aliyuncs.com/compatible-mode/v1",
)

def get_response(messages):
    completion = client.chat.completions.create(
        model="qwen-plus",
        messages=messages
    )
    return completion.choices[0].message.content

# åˆå§‹åŒ– messages
messages = []

# ç¬¬ 1 è½®
messages.append({"role": "user", "content": "æ¨èä¸€éƒ¨å…³äºå¤ªç©ºæ¢ç´¢çš„ç§‘å¹»ç”µå½±ã€‚"})
print("ç¬¬1è½®")
print(f"ç”¨æˆ·ï¼š{messages[0]['content']}")
assistant_output = get_response(messages)
messages.append({"role": "assistant", "content": assistant_output})
print(f"æ¨¡å‹ï¼š{assistant_output}\n")

# ç¬¬ 2 è½®
messages.append({"role": "user", "content": "è¿™éƒ¨ç”µå½±çš„å¯¼æ¼”æ˜¯è°ï¼Ÿ"})
print("ç¬¬2è½®")
print(f"ç”¨æˆ·ï¼š{messages[-1]['content']}")
assistant_output = get_response(messages)
messages.append({"role": "assistant", "content": assistant_output})
print(f"æ¨¡å‹ï¼š{assistant_output}\n")

# ç¬¬ 3 è½®
messages.append({"role": "user", "content": "è¿™éƒ¨ç”µå½±çš„ç”·ä¸»è§’å’Œå¥³ä¸»è§’æ˜¯è°ï¼Ÿ"})
print("ç¬¬3è½®")
print(f"ç”¨æˆ·ï¼š{messages[-1]['content']}")
assistant_output = get_response(messages)
messages.append({"role": "assistant", "content": assistant_output})
print(f"æ¨¡å‹ï¼š{assistant_output}\n")